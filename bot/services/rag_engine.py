# bot/services/rag_engine.py
import os
import chromadb
import requests
import base64
import uuid
import time
from typing import List
import urllib3

tr_text = 1000
chunk_size = 200
n_res = 3

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω–æ–º SSL
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class RAGEngine:
    def __init__(self, docs_path: str = "data/docs", db_path: str = "data/chroma_db"):
        self.docs_path = docs_path
        self.db_path = db_path

        # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è GigaChat
        self.GIGACHAT_CLIENT_ID = os.getenv("GIGACHAT_CLIENT_ID")
        self.GIGACHAT_SECRET = os.getenv("GIGACHAT_SECRET")
        if not self.GIGACHAT_CLIENT_ID or not self.GIGACHAT_SECRET:
            raise EnvironmentError("GIGACHAT_CLIENT_ID –∏ GIGACHAT_SECRET –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –∑–∞–¥–∞–Ω—ã –≤ .env")

        self.access_token = None
        self._refresh_token()

        # ChromaDB
        self.client = chromadb.PersistentClient(path=db_path)
        self.collection = self.client.get_or_create_collection("ecofes_docs")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏ –∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        self._load_and_index_docs()

    def _refresh_token(self):
        """–ü–æ–ª—É—á–∞–µ—Ç –Ω–æ–≤—ã–π access_token —á–µ—Ä–µ–∑ OAuth"""
        credentials = f"{self.GIGACHAT_CLIENT_ID}:{self.GIGACHAT_SECRET}"
        encoded_credentials = base64.b64encode(credentials.encode()).decode()

        url = "https://ngw.devices.sberbank.ru:9443/api/v2/oauth"
        headers = {
            "Authorization": f"Basic {encoded_credentials}",
            "RqUID": str(uuid.uuid4()),
            "Content-Type": "application/x-www-form-urlencoded",
            "Accept": "application/json"
        }
        data = {"scope": "GIGACHAT_API_PERS"}

        try:
            response = requests.post(url, headers=headers, data=data, verify=False)
            response.raise_for_status()
            self.access_token = response.json()["access_token"]
            print("‚úÖ access_token —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω")
        except requests.exceptions.HTTPError as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ç–æ–∫–µ–Ω–∞: {e.response.status_code} {e.response.text}")
            raise

    def _get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–∞–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥ —á–µ—Ä–µ–∑ GigaChat API"""
        url = "https://gigachat.devices.sberbank.ru/api/v1/embeddings"
        headers = {
            "Authorization": f"Bearer {self.access_token}",
            "Content-Type": "application/json",
            "Accept": "application/json"
        }
        # –£—Å–µ–∫–∞–µ–º –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
        truncated_text = text[:tr_text]  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ —Å–∏–º–≤–æ–ª–∞–º
        payload = {
            "model": "Embeddings",
            "input": [truncated_text]
        }

        try:
            response = requests.post(url, headers=headers, json=payload, verify=False)
            if response.status_code == 401:  # Unauthorized
                print("üîê –¢–æ–∫–µ–Ω —É—Å—Ç–∞—Ä–µ–ª. –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤—ã–π...")
                self._refresh_token()
                headers["Authorization"] = f"Bearer {self.access_token}"
                response = requests.post(url, headers=headers, json=payload, verify=False)

            response.raise_for_status()
            return response.json()["data"][0]["embedding"]

        except requests.exceptions.HTTPError as e:
            if response.status_code == 413:
                print(f"‚ùå –¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π –¥–ª—è GigaChat: '{text[:500]}...'")
            else:
                print(f"‚ùå –û—à–∏–±–∫–∞ {response.status_code}: {response.text}")
            raise
        except Exception as e:
            print(f"‚ùå –ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {e}")
            raise

    def _split_text(self, text: str, chunk_size: int = chunk_size) -> List[str]:
        """–†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤"""
        words = text.split()
        return [" ".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]

    def _load_and_index_docs(self):
        import glob
        import os

        doc_files = list(glob.glob(f"{self.docs_path}/**/*.*", recursive=True))
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(doc_files)}")

        if self.collection.count() > 0:
            print(f"‚úÖ –ö–æ–ª–ª–µ–∫—Ü–∏—è —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç {self.collection.count()} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
            return

        documents = []
        metadatas = []
        ids = []
        debug_file = dict()

        for file_path in doc_files:
            try:
                with open(file_path, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                    if len(content) < 10:
                        print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª: {file_path}")
                        continue

                    chunks = self._split_text(content, chunk_size=chunk_size)  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    print(f"‚úÇÔ∏è –§–∞–π–ª {os.path.basename(file_path)} —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤")

                    for i, chunk in enumerate(chunks):
                        doc_id = f"{os.path.basename(file_path)}_{i}"
                        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —á–∞–Ω–∫–∞ –ø–µ—Ä–µ–¥ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ–º
                        if len(chunk) > tr_text*2:
                            print(f"‚ö†Ô∏è –ß–∞–Ω–∫ {doc_id} —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π ({len(chunk)} —Å–∏–º–≤–æ–ª–æ–≤), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                            continue
                        documents.append(chunk)
                        metadatas.append({"source": file_path})
                        ids.append(doc_id)
                        debug_file[i] = [file_path,chunk]
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {file_path}: {e}")

        if documents:
            print(f"üì¶ –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º {len(documents)} —á–∞–Ω–∫–æ–≤...")
            embeddings = []
            for i, doc in enumerate(documents):
                print(f"üåê –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥ {i + 1}/{len(documents)}")
                try:
                    emb = self._get_embedding(doc)
                    embeddings.append(emb)
                except Exception:
                    print(f"‚ùå –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —á–∞–Ω–∫ {i + 1} –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏")
                    continue  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—Ä–æ–±–ª–µ–º–Ω—ã–π —á–∞–Ω–∫
                time.sleep(0.1)  # –ê–Ω—Ç–∏-—Ñ–ª—É–¥

            if embeddings:
                self.collection.add(ids=ids, embeddings=embeddings, documents=documents, metadatas=metadatas)
                print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ {len(embeddings)} —á–∞–Ω–∫–æ–≤")
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–≥–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞")
        else:
            print("‚ùå –ù–ï–¢ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.")

    def search(self, query: str, n_results: int = n_res) -> List[str]:
        """–ü–æ–∏—Å–∫ –ø–æ –∑–∞–ø—Ä–æ—Å—É"""
        try:
            query_embedding = self._get_embedding(query)
            results = self.collection.query(query_embeddings=[query_embedding], n_results=n_results)
            return results["documents"][0] if results["documents"] else []
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
            return []
